# Quick Start: Training Your First Model

Get your malware detection model trained in under 30 minutes.

## Prerequisites

- DGX Spark access (or local GPU with 16GB+ VRAM)
- ~500GB free disk space
- Conda or Python 3.10+

## Step 1: Setup (5 minutes)

```bash
cd src-ml
./setup_dgx.sh
conda activate custos-ml
```

## Step 2: Download Mini Dataset (10 minutes)

For quick testing, use a subset:

```bash
# Create data directories
mkdir -p data/raw/sorel

# Download small sample (100K instead of 10M)
# Option 1: Download from Sorel-20M
wget https://sorel-20m.s3.amazonaws.com/sorel-20m-sample-100k.tar.gz
tar -xzf sorel-20m-sample-100k.tar.gz -C data/raw/sorel

# Option 2: Use Ember (smaller, 1.1M samples)
pip install ember
python -c "import ember; ember.create_vectorized_features('./data/raw/ember')"
```

## Step 3: Train XGBoost (10 minutes)

Train a baseline model:

```bash
python scripts/train_xgboost.py \
    --data-dir ./data/raw/sorel \
    --max-samples 100000 \
    --output-dir ./outputs/models
```

**Expected Output**:
```
[1/5] Loading dataset...
Loaded 100,000 samples
Malware: 50,000 | Benign: 50,000

[2/5] Creating DMatrix...

[3/5] Configuring model...
GPU acceleration enabled

[4/5] Training model...
[0] train-logloss:0.45 val-logloss:0.46
[10] train-logloss:0.12 val-logloss:0.13
[20] train-logloss:0.05 val-logloss:0.06
...

[5/5] Evaluating model...
Accuracy:  98.50%
Precision: 98.20%
Recall:    99.10%
ROC-AUC:   99.80%
FPR:       0.018%

‚úÖ Model saved: outputs/models/xgboost_malware_20260126_153045.json
‚úÖ ONNX exported: outputs/onnx/xgboost_malware_20260126_153045.onnx
```

## Step 4: Test Your Model (5 minutes)

Test the trained model on a file:

```python
# test_model.py
import xgboost as xgb
import numpy as np
from features.extractors.static_features import StaticFeatureExtractor

# Load model
model = xgb.Booster()
model.load_model('outputs/models/xgboost_malware_20260126_153045.json')

# Extract features from a file
extractor = StaticFeatureExtractor()
features = extractor.extract('/path/to/suspicious/file.exe')

# Convert to feature vector (2381 features)
feature_vector = np.array([...])  # Convert dict to array

# Predict
dtest = xgb.DMatrix(feature_vector.reshape(1, -1))
probability = model.predict(dtest)[0]

if probability > 0.5:
    print(f"‚ö†Ô∏è  MALWARE DETECTED (confidence: {probability:.2%})")
else:
    print(f"‚úÖ File appears benign (confidence: {1-probability:.2%})")
```

## Full Dataset Training

Once you're ready for production:

### Download Full Sorel-20M (~2-3 hours)

```bash
cd data/raw/sorel

# Download metadata (8GB)
wget https://sorel-20m.s3.amazonaws.com/sorel-20m-metadata.tar.gz
tar -xzf sorel-20m-metadata.tar.gz

# Download features (300GB)
wget https://sorel-20m.s3.amazonaws.com/sorel-20m-features.tar.gz
tar -xzf sorel-20m-features.tar.gz
```

### Train Full Model (~3-4 hours on DGX)

```bash
# XGBoost (fastest)
python scripts/train_xgboost.py

# Neural Network Ensemble (best accuracy)
python scripts/train_neural_net.py --model ensemble --epochs 100
```

## Production Deployment

Export to ONNX for use in the Tauri app:

```bash
# ONNX is already exported during training
cp outputs/onnx/xgboost_malware_latest.onnx \
   ../../src-tauri/models/malware_detector.onnx
```

Integrate into Rust scanning engine:

```rust
// src-tauri/src/malware/ml_scanner.rs
use onnxruntime::{environment::Environment, GraphOptimizationLevel, LoggingLevel};

pub struct MLScanner {
    env: Environment,
    session: Session<'_>,
}

impl MLScanner {
    pub fn new() -> Result<Self> {
        let env = Environment::builder()
            .with_name("malware_detection")
            .with_log_level(LoggingLevel::Warning)
            .build()?;

        let session = env
            .new_session_builder()?
            .with_optimization_level(GraphOptimizationLevel::All)?
            .with_model_from_file("models/malware_detector.onnx")?;

        Ok(Self { env, session })
    }

    pub fn scan_file(&self, features: Vec<f32>) -> Result<f32> {
        // features is 2381-element vector
        let input_tensor = ndarray::Array::from_shape_vec((1, 2381), features)?;

        let outputs = self.session.run(vec![input_tensor])?;
        let probability = outputs[0].extract_tensor::<f32>()?[[0, 0]];

        Ok(probability)
    }
}
```

## Monitoring Training

### Option 1: Weights & Biases

```bash
export WANDB_API_KEY=your_key
export WANDB_PROJECT=custos-ml

python scripts/train_neural_net.py --model ensemble
```

View at: https://wandb.ai

### Option 2: TensorBoard

```bash
tensorboard --logdir ./logs --port 6006
```

Open: http://localhost:6006

## Troubleshooting

### "FileNotFoundError: Dataset not found"
- Download the dataset first (see Step 2)
- Check paths in command

### "CUDA out of memory"
- Reduce batch size: `--batch-size 128`
- Use smaller model: `--model mlp`
- Close other GPU applications

### "Slow training"
- Use GPU: Model automatically uses GPU if available
- Increase workers: `--num-workers 16`
- Check GPU utilization: `nvidia-smi`

### "Low accuracy (<95%)"
- Train on more data (use full 10M samples)
- Train longer: `--epochs 100`
- Try ensemble model: `--model ensemble`

## Next Steps

1. **Collect more data**: Add custom malware samples
2. **Fine-tune**: Adjust hyperparameters for your use case
3. **Deploy**: Integrate ONNX model into Tauri app
4. **Monitor**: Track false positives in production
5. **Update**: Retrain monthly with new threat data

## Support

Questions? Check:
- `README.md` - Full documentation
- `IMPLEMENTATION_PLAN.md` - Development roadmap
- `WEEK1_PROGRESS.md` - Progress report

---

**Time to first model**: ~30 minutes
**Time to production model**: ~4 hours (with full dataset)
**Expected accuracy**: 98-99.5%
**False positive rate**: <0.01%

Happy training! üöÄ
